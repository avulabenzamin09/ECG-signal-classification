{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etHkGfLQOp7C"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import optimizers, losses, activations, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
        "    concatenate\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_train = pd.read_csv(\"/content/drive/My Drive/ecg/mitbih_train.csv\", header=None)\n",
        "dt_train = dt_train.sample(frac=1)\n",
        "dt_test = pd.read_csv(\"/content/drive/My Drive/ecg/mitbih_test.csv\", header=None)\n",
        "\n",
        "train_y = np.array(dt_train[187].values).astype(np.int8)\n",
        "train_x = np.array(dt_train[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "test_y = np.array(dt_test[187].values).astype(np.int8)\n",
        "test_x = np.array(dt_test[list(range(187))].values)[..., np.newaxis]"
      ],
      "metadata": {
        "id": "AOQ0fmHXOssz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(train_y)\n",
        "train_y.shape\n",
        "test_y = to_categorical(test_y)\n",
        "test_y.shape"
      ],
      "metadata": {
        "id": "kLgnbHibO9m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv1D(32, kernel_size=5,strides=1, padding=\"valid\",input_shape=[187,1],activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv1D(32, kernel_size=5,strides=2,  padding='valid',activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv1D(64, kernel_size=5,strides=2, padding='valid',activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv1D(128, kernel_size=5,strides=2, padding='valid',activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv1D(256, kernel_size=5,strides=2, padding='valid',activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256,activation='tanh'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(5,activation='tanh'))\n",
        "model.add(layers.Softmax())"
      ],
      "metadata": {
        "id": "v721MCaKOvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/My Drive/baseline_cnn_mitbih.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early"
      ],
      "metadata": {
        "id": "KuFd761YPHF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
        "model.fit(train_x, train_y, epochs=1000,batch_size=10000, validation_split=0.1)"
      ],
      "metadata": {
        "id": "yGN9kh4hOzZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(file_path)"
      ],
      "metadata": {
        "id": "64q0ypRbO-6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = model.predict(test_x)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "f1 = f1_score(test_y, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(test_y, pred_test)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)"
      ],
      "metadata": {
        "id": "20_nyq9RPQgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}